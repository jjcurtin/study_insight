---
title: "Dynamic Self-Monitoring Predicts Future Alcohol Use" 
author: "Gaylen Fronk, M.S."
institute: "University of Wisconsin-Madison"
format: 
  revealjs:
    incremental: false
    scrollable: true
    chalkboard: false
    css: slides.css
    background-color: dark-gray
fig-cap-location: top
editor_options: 
  chunk_output_type: console
---
## Acknowledgements

:::: {.columns}

::: {.column width="40%"}
- Project Co-Authors
  - Ariela Papp
  - Kendra Wyant
  - Sarah Sant'Ana
  - John Curtin (PI)
:::

::: {.column width="60%"}
- Parent Project
  - Susan Wanta (project administration, data curation)
  - Candace Lightheart (data collection)
  - Kerry Keiser (data collection)
  - Megan Schultz (data collection)
  - Jill Nagler (data collection)
  - Chris Gioia (clinical supervision)
  - Xiaojin (Jerry) Zhu (project conceptualization, analyses)
:::

::::

- Funding
  - This research was supported by grants from NIAAA (R01 AA024391; Curtin) and NIDA (R01 DA047315; Curtin)
  - This investigator was supported by a grant from NIDA (F31 DA056144; Fronk)
  
::: {.notes}
I want to start by thanking the many people who have contributed to this work. This includes the co-authors for this project, the host of people who helped design and run its parent project, and the NIAAA and NIDA for funding my advisor John Curtin and myself.
:::
  
## Acknowledgements

:::: {.columns}

::: {.column width="40%"}
- Project Co-Authors
  - [Ariela Papp]{.yellow}
  - Kendra Wyant
  - Sarah Sant'Ana
  - John Curtin (PI)
:::

::: {.column width="60%"}
- Parent Project
  - Susan Wanta (project administration, data curation)
  - Candace Lightheart (data collection)
  - Kerry Keiser (data collection)
  - Megan Schultz (data collection)
  - Jill Nagler (data collection)
  - Chris Gioia (clinical supervision)
  - Xiaojin (Jerry) Zhu (project conceptualization, analyses)
:::

::::

- Funding
  - This research was supported by grants from NIAAA (R01 AA024391; Curtin) and NIDA (R01 DA047315; Curtin)
  - This investigator was supported by a grant from NIDA (F31 DA056144; Fronk)
  
::: {.notes}
This is also just a quick plug that Ariela, one of our wonderful research techs, will be presenting on a follow-up to this project in Saturday morning;s poster session. Please go check out her poster!
:::

## Self-monitoring during AUD recovery

[Self-monitoring]{.yellow} is a tool to increase conscious awareness about one's own present or future behavior

::: {.notes}
In the literature, self-monitoring = insight = confidence/likelihood of behaviors = future self-efficacy. No matter the name, it is a tool to bring about awareness of current behaviors, and to encourage thinking about the likelihood of future behaviors
:::

## Self-monitoring during AUD recovery

[Self-monitoring]{.yellow} is a tool to increase conscious awareness about one's own present or [future]{.yellow} behavior

::: {.notes}
In the case of alcohol use disorder (AUD), self-monitoring is often used to increase awareness about CURRENT RISK of FUTURE ALCOHOL USE, especially a return to drinking that is goal-inconsistent. For example, if someone's goal is abstinence, then they may wish to self-monitor risk of any alcohol use.
:::

## Self-monitoring during AUD recovery

[Self-monitoring]{.yellow} is a tool to increase conscious awareness about one's own present or [future]{.yellow} behavior

Self-monitoring is...

- Encouraged by clinicians

- Included in many self-help tools/apps/etc.

- Considered to be a productive component of CBT in the treatment of substance use disorders

::: {.notes}
There is a strongly held belief that self-monitoring is a valuable and even necessary tool during AND FOLLOWING treatment for alcohol use disorder (AUD). Often, self-monitoring is encouraged by clinicians as a primary tool post-treatment as a way for individuals to determine whether they need to reach back out for support. It is also a key component of many self-help tools or apps, like via behavior tracking. 
:::

## Static measurement
::: {.incremental}
- Self-monitoring has traditionally been measured [statically]{.yellow}

  - These measures are often used to assess an individual's "long-term" likelihood of remaining abstinent
  
  - Scores from these measures may be used at the end of treatment/end of study/etc. to estimate an individual's future likelihood of staying abstinent

- It is unclear [how well static measures of future risk predict future lapse and relapse outcomes]{.yellow}.
:::

::: {.notes}
Self-monitoring has traditionally been measured statically. When I say static, I mean that a single measurement may be expected to assess risk for a very long period of time. Consequently, these measures are often used to assess "long-term" likelihood of remaining abstinent. These scores can then be used to measure success at the end of a research study or to determine whether an individual is ready to end treatment. However, although they are used this way, it is unclear how well static measures of future risk predict future lapse and relapse outcomes.
:::

## Recovery as a dynamic process

::: {.incremental}
- Risk of lapse/relapse is best understood [dynamically]{.yellow}

  - Relapse prevention model has been updated to reflect dynamic processes
  
  - Fluctuating risk over time due to fluctuating proximal and distal risk factors that interact fluidly with one another
  
- Thus, self-monitoring dynamic risk of lapse likely requires [dense, dynamic assessment]{.yellow} to be effective
:::

::: {.notes}
Static or one-time measurement stands in conflict with what we know about recovery, which is that it is best understood dynamically. The relapse prevention model has been updated by Katie Witkiewitz and others to reflect dynamic processes. When I say dynamic, what I mean is that risk fluctuates over time due to ever-changing proximal and distal risk factors that interact fluidly with one another. Thus, if individuals are to monitor their own dynamic risk, they likely need dense, dynamic assessment tools.
:::

::: {.notes}

:::

## Purpose {.larger}

The purpose of this project was to determine whether we can predict alcohol lapse more accurately using [dynamic self-monitoring]{.yellow} or [static (one-time) risk assessment]{.yellow}.

## Participants

::: {.columns} 

:::: {.column width="50%"}
- Participants in early recovery (1-8 weeks abstinence) from moderate or severe AUD

  - All participants had a goal of abstinence
  
  - Participants were on-study for up to 3 months
::::

:::: {.column width="50%"}

::::

:::

::: {.notes}
We recruited participants who were in early recovery from moderate or severe AUD. Specifically, our participants were 1-8 weeks abstinent at study start. All participants in this project had a goal of abstinence. Participants were on-study for up to 3 months.
:::

## Participants

::: {.columns} 

:::: {.column width="50%"}
- Participants in early recovery (1-8 weeks abstinence) from moderate or severe AUD

  - All participants had a goal of abstinence
  
  - Participants were on-study for up to 3 months
::::

:::: {.column width="50%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/demo_table.png)
::::

:::
  
::: {.notes}
Here are a few demographic characteristics of our sample. We had good representation in terms of sex, and participants ranged in age from 21 to 72. We had a predominantly White, non-Hispanic sample, so we can keep that in mind as a limitation throughout.
:::

## Static risk assessment via AASE

- During an intake visit, participants completed the [Alcohol Abstinence Self-Efficacy Scale (AASE)]{.yellow} (McKiernan et al., 2013)

::: {.incremental}
- 20-item version that comprises the [confidence domain]{.yellow} of the 40-item version

  - Measures an individual's *self-confidence about their ability to avoid drinking alcohol* in a variety of situations
  
  - Response options range from 0 ("Not at all") to 4 ("Extremely")
  
- Total score is calculated by summing all item scores
:::

::: {.notes}
During an intake visit, participants completed the Alcohol Abstinence Self-Efficacy Scale or AASE. We used a 20-item version that comprises the confidence domain of the briefer, 40-item version of the AASE developed by McKiernan at all. These items collectively measure an individual's self-confidence about their ability to avoid drinking alcohol in a variety of situations. Response options range from 0 to 4, and the total score is calculated by summing all 20 item scores.
:::

## Dynamic self-monitoring via EMA

:::: {.columns}

::: {.column width="70%"}

- Dynamic self-monitoring relied on a single EMA item:

> "How likely are you to drink any alcohol in the next week?"

:::

::: {.column width="30%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/ema_insight_mobile.png)
:::

::::

::: {.notes}
Ecological momentary assessment (EMA) offers a method by which individuals can self-monitor both densely and longitudinally. Self-monitoring was captured by a single EMA item, "How likely are you to drink any alcohol in the next week?" As a reminder, our sample has a goal of abstinence, so "any drinking" is goal-inconsistent for them
:::

## Dynamic self-monitoring via EMA

:::: {.columns}

::: {.column width="70%"}

- Dynamic self-monitoring relied on a single EMA item:

> "How likely are you to drink any alcohol in the next week?"

- This item appeared on a 10-item EMA survey that assessed relevant risk factors
  - 7 items about current state/behaviors since last EMA (e.g., urges)

:::

::: {.column width="30%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/ema_adtl_qs_1.png)
:::

::::

::: {.notes}
This item appeared on a 10-item EMA survey that assessed relevant risk factors. The first 7 items assessed current states or behaviors since their last EMA, for example urges. 
:::

## Dynamic self-monitoring via EMA

:::: {.columns}

::: {.column width="70%"}

- Dynamic self-monitoring relied on a single EMA item:

> "How likely are you to drink any alcohol in the next week?"

- This item appeared on a 10-item EMA survey that assessed relevant risk factors
  - 7 items about current state/behaviors since last EMA (e.g., urges)
  - 2 additional next-week reflections (e.g., likelihood of stressful event)
  - Self-monitoring

:::

::: {.column width="30%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/ema_adtl_qs_2.png)
:::

::::

::: {.notes}
There were then two additional questions estimating likelihood of events in the next week, for example upcoming stressful events, and the self-monitoring item.
:::

## Dynamic self-monitoring via EMA

:::: {.columns}

::: {.column width="70%"}

- EMA surveys were sent [four times daily]{.yellow}
  - Only *morning EMA surveys* contained final three items about next-week risk, including self-monitoring
  - Previous work from our laboratory showed providing 4X daily EMA data in this study was acceptable to and well-tolerated by participants (Wyant et al., 2023)

:::

::: {.column width="30%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/ema_adtl_qs_2.png)
:::

::::

::: {.notes}
EMA surveys were sent 4 times daily. Only the morning EMA surveys - the first survey each day - contained the final 3 items about next-week risk including the self-monitoring item. Previous work from our laboratory has shown that the participants in this study found providing 4x daily EMA to be acceptable and well-tolerated.
:::

## Dynamic self-monitoring via EMA

:::: {.columns}

::: {.column width="70%"}

- EMA surveys were sent [four times daily]{.yellow}
  - Only *morning EMA surveys* contained final three items about next-week risk, including self-monitoring
  - Previous work from our laboratory showed that providing 4X daily EMA data in this study was acceptable to and well-tolerated by participants (Wyant et al., 2023)

- Thus, self-monitoring was:
  - [Dynamic]{.yellow}: Assessed daily, able to capture fluctuations
  - [Cued]{.yellow}: Individuals were prompted to reflect on their risk
  - [Contextualized]{.yellow}: Final item in survey, required first reflecting on nine relevant risk factors

:::

::: {.column width="30%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/ema_adtl_qs_2.png)
:::

::::

::: {.notes}
Thus, as assessed in this way, self-monitoring was dynamic and able to capture daily fluctuations. It was also cued, because individuals were prompted to complete these surveys. Finally, it was contextualized - because self-monitoring was the final item in the survey, participants had to reflect on nine risk factors before estimating their next-week risk.
:::

## Outcome: Lapse

:::: {.columns}

::: {.column width="70%"}

- [Lapse]{.yellow}: A single instance of goal-inconsistent alcohol use

:::

::: {.column width="30%"}
:::

::::

::: {.notes}
Our outcome was lapse, which we defined as a single instance of goal-inconsistent use. As a reminder, our sample had a goal of abstinence, so any drinking was goal-inconsistent.

We chose to use lapse as our outcome because it is observable, has a temporally precise onset and offset, and is more clearly defined than a broader outcome like relapse. Lapses also always precede relapse and can be an early warning sign for intervention.
:::

## Outcome: Lapse

:::: {.columns}

::: {.column width="70%"}

- [Lapse]{.yellow}: A single instance of goal-inconsistent alcohol use

- Lapses were assessed via EMA (first item on all 4 daily surveys):

> "Have you drank any alcohol that you have not yet reported?

:::

::: {.column width="30%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/ema_lapse_mobile.png)
:::

::::

::: {.notes}
Lapses were assessed via the first item on all four daily EMA surveys, which was "Have you drank any alcohol that you have not yet reported?" 
:::

## Outcome: Lapse

:::: {.columns}

::: {.column width="70%"}

- [Lapse]{.yellow}: A single instance of goal-inconsistent alcohol use

- Lapses were assessed via EMA (first item on all 4 daily surveys):

> "Have you drank any alcohol that you have not yet reported?

- If participants answered yes to this question, they were prompted to enter:

  - The hour and date of the start of the drinking episode
  
  - The hour and date of the end of the drinking episode

:::

::: {.column width="30%"}
![](https://raw.githubusercontent.com/jjcurtin/study_insight/main/images/ema_cal_mobile.png)
:::

::::

::: {.notes}
If participants answered yes to this question, they were prompted to enter the date and hour of the start and end of the drinking episode.
:::

## Lapse labels

::: {.incremental}
- Our outcomes were [one-week windows]{.yellow} that began immediately following the submission of the morning EMA survey to map onto the next week drinking of the self-monitoring question

- Weeks were labeled as [lapse]{.yellow} or [no lapse]{.yellow}

- Total N observations (i.e., 1-week windows): 9845

  - Lapse: 2442 (24.8%)
  
  - No lapse: 7403 (75.2%)
:::

::: {.notes}
Our outcomes were one-week windows that began immediately following the submission fo the morning EMA survey. This ensured that our one-week outcome windows lined up with the next week of drinking referenced in the self-monitoring question. If the week period contained a lapse, it was labeled as lapse; if not, it was labeled as no lapse. From our 151 particpants, this produced just under 10000 observations, of which 25% were labeled lapse and 75% were labeled as no lapse.
:::

## Model training, selection, & evaluation

- Single predictor in each model: 
  - [Static risk assessment]{.yellow}: AASE total score (same score for all outcome windows)
  - [Dynamic self-monitoring]{.yellow}: most recent self-monitoring score from EMA item
  
- Outcome: next-week drinking

::: {.notes}
Our models to assess static and dynamic self-monitoring each had only one predictor in the model, either their total AASE score from intake, or their most recent self-monitoring score from the EMA item. The outcome was next-week drinking.
:::

## Model training, selection, & evaluation

- Single predictor in each model: 
  - [Static risk assessment]{.yellow}: AASE total score (same score for all outcome windows)
  - [Dynamic self-monitoring]{.yellow}: most recent self-monitoring score from EMA item

- Outcome: next-week drinking

- Models are trained and evaluated using [cross-validation]{.yellow}
  - Evaluated in *held-out data* (i.e., data not used for training)
  - Produces 30 independent estimates of model performance

::: {.notes}
Our models were trained and evaluated using a cross-validation procedure. I'm happy to talk more about these methods if people have questions, but what's important to know is that models were evaluated in held-out data, meaning data that were not used to train those models. Our cross-validation method produces 30 independent estimates of model performance for our dynamic and static models.
:::

## Model training, selection, & evaluation

- Single predictor in each model: 
  - [Static risk assessment]{.yellow}: AASE total score (same score for all outcome windows)
  - [Dynamic self-monitoring]{.yellow}: most recent self-monitoring score from EMA item
  
- Outcome: next-week drinking

- Models are trained and evaluated using [cross-validation]{.yellow}
  - Evaluated in *held-out data* (i.e., data not used for training)
  - Produces 30 independent estimates of model performance
  
- Model performance evaluated on [area under the ROC curve (auROC)]{.yellow}
  - Chance performance: **auROC = 0.5**
  - Perfect prediction: **auROC = 1.0**

::: {.notes}
Model performance was evaluated on area under the ROC curve, or auROC. This metric indexes how well our model can discriminate between lapse and no lapse cases. auROC ranges from 0.5, chance performance, to 1, perfect prediction with every case correctly classified. So, for our analyses, we had 30 auROCs from held-out data for both models.
:::

## Analysis plan: Model performance comparisons

::: {.incremental}
- We used a [Bayesian hierarchical generalized linear model]{.yellow} to estimate the posterior probability distributions around auROCs for the best models

  - Posterior probability: the likelihood *given our data*

- [Model performance]{.yellow}: posterior probability distributions around model performance --> do they include 0.5?

- [Model comparison]{.yellow}: probability (% chance) that one model performs better than another
:::

::: {.notes}
we can then compare these performance estimates using a bayesian hierarchical generalized linear model, following recommendations from the tidymodels team

these Bayesian approaches produce posterior probability distributions, which are distributions of the likelihood of the model's performance given our data

to determine whether a model has predictive signal, we can see whether that posterior probability distribution includes 0.5 (chance performance)

we can also compare these distributions from our two models to determine the probability that one model performs better than another
:::

## Results: Dynamic vs. static self-monitoring

{{< embed ../notebooks/ana_bayes_insight.qmd#post-model-sm >}}

::: {.notes}
along the x axis is auROC, our model performance metric. as a reminder, the maximum possible range is from about 0.5 (chance performance) to 1.0 (perfect prediction)

In the top panel in pink, we see AASE performance. There is some signal as the posterior distribution does not include 0.5. This is unsurprising given extant literature and its continued use in clinical practice! However, it's not very accurate - Individuals can predict their lapses on-study only slightly more accurately than chance performance
:::

## Results: Dynamic vs. static self-monitoring

{{< embed ../notebooks/ana_bayes_insight.qmd#post-model-sm >}}

::: {.notes}
In the bottom panel in teal, we can see that dynamic self-monitoring allows our participants to do SO MUCH better! This makes sense because we are assessing a process that we know to be dynamic. They can now quite accurately predict their alcohol use in the coming week. this model has an auROC of 0.8, and there is a 99.99% chance that this dynamic model predicts better than the static risk model. I also want to point out that the difference in auROCs between these models is about 0.2, which is arounnd 40% of the range in auROC - that's a huge effect size!
:::

## Takeaways

::: {.incremental}
- Individuals can predict their likelihood of future alcohol lapses at study intake (via the AASE) better than chance but with very low accuracy
  - Insufficient for prediction and clinical utility
  - Likely to continue degrading over time

- When participants can self-monitor dynamically, they can predict their risk of lapsing in the next week quite accurately
  - Supports the long-believed value of self-monitoring with empirical evidence
  - Offers nuance regarding the need for dynamic, cued, and contextualized assessment
  - Might be empowering to individuals! 

- From an implementation standpoint, [we cannot do much with predictions based solely on self-monitoring]{.yellow}

:::

::: {.notes}
We learned that individuals can predict their likelihood of lapsing with the AASE better than chance but with very low accurately. This level of performance is insufficient for prediction and clinical utility. Also, this model's performance is likely to degrade over time as the time between the assessment and outcome continues to grow.

When participants can self-monitoring dynammically, they can predict their risk quite accurately. This finding supports the value of self-monitoring empirically, and it offers nuance regarding the need for dynamic, cued, and contextualized assessment. Also, knowing that you are in tune with your own risk might be quite empowering to individuals!

However, from an implementation standpoint, we cannot do much with predictions based solely on self-monitoring. This model predicts relatively well, but perhaps not yet well enough. More importantly, it does not offer guidance as to what to do next - we only know that they likely are at risk, but we don't have information about WHY or how we might intervene.
:::

## Purpose {.larger}

Can we obtain [more accurate, more clinically useful predictions]{.yellow} by taking advantage of additional EMA data?

::: {.notes}
So, we wanted to know - can we obtain more accurate, more clinically useful predictions by taking advantage of additional EMA data? We will build a model using all the items from the 4X daily EMA surveys and predict the same 1-week outcomes. We'll follow our same model comparison approach and see what we gain with these additional data.
:::

## Model training, selection, & evaluation

::: {.incremental}
- Predictors in each model: 

  - [Static risk]{.yellow}: total AASE score only

  - [Dynamic self-monitoring]{.yellow}: most recent self-monitoring score
  
  - [All EMA]{.yelllow}: all items from 4X daily EMA surveys

- Outcome: next-week drinking
::: 

::: {.notes}
We have our same first two models with static risk and dynamic self-monitoring only, and we now have a third model using all items from the 4X daily EMA surveys. We predicted the same next-week drinking outcome. We fit this model with all the EMA data using the same cross-validation process to produce 30 independent auROCs. We can then evaluate model performance and compare performance across models just like before. I'll present the results to you in the same way.
:::

## Results: All EMA features vs. self-monitoring alone

{{< embed ../notebooks/ana_bayes_insight.qmd#post-model-all >}}

::: {.notes}
Again, we have auROc across the x-axis where the possible range is 0.5 to 1. In the top two panels, we have our static and dynamic self-monitoring model performance that you've seen before. 

In the bottom panel, we have our new all-EMA model performance, which has a median auROC of 0.88. There is a 99.99% chance that this model performs better than dynamic self-monitoring alone. The difference between these two models is just under .1, which is about 20% of the possible range, so another big effect size!
:::

## Application: How can we use this?

::: {.incremental}
- With more EMA data in the model, performance becomes sufficiently accurate for clinical implementation --> the model can generate relatively reliable probabilities of lapsing in the next week

- We can also take advantage of techniques that can identify the importance of different predictors in *affecting* those probabilities

- This would allow us to know, *for a given person on a given day*:
  - Their [probability of lapsing]{.yellow} in the next week
  - The [risk factors]{.yellow} driving that probability

- Ultimately, this could permit selecting interventions that target those risk factors!
:::

::: {.notes}
So, how can we use this? With more EMA data in the model, performance becomes sufficiently accurate for clinical implementation. The model could generate relatively reliable probabilities of lapsing in the next week.

Now that we have a model with many predictors, we can also take advantage of techniques that can identify the importance of different predictors in affecting those probabilities. We can assess not only global importance - importance across observations - but also local importance - the importance for a single observation. This would allow us to know, for a given person on a given day, their probability of lapsing in the next week AND the risk factors driving that probability.

For example, let's say that an individual has a high probability of lapsing in the next week. We can unpack the model to learn that that person's probability of lapsing is currently being increased because they have been experiencing high craving. 

Ultimately, this could permit selecting interventions that target those risk factors. For our person with high risk due to high craving, we might suggest a stimulus control technique like leaving their current environment.

These treatments could even be tailored to consider both the relevant risk factors and the probabilities themselves. For example, if someone is experiencing high craving but has a low risk of lapsing, we might suggest coping in place (maybe with urge surfing) rather than leaving the environment.

Overall, a model like this not only gives us much more information but also gives us paths forward for clinical action!

ONLY ADVANCE IF TIME IS REMAINING
:::

## Conclusions

::: {.incremental}
- Though above chance performance, individuals can only predict ongoing risk of lapse during early recovery using static assessment with extremely low accuracy

- Dynamic self-monitoring via EMA allows individuals to predict changing next-week lapse risk relatively accurately

  - ... when self-monitoring is cued and contextualized
  
- Incorporating additional EMA data:

  - Improves prediction accuracy
  
  - Offers context about contributing risk factors
  
  - Creates a model that is well-positioned to offer actionable clinical utility

:::