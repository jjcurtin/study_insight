---
title: "Dynamic Assessment of Self-Efficacy Predicts Future Alcohol Use" 
author: "Gaylen Fronk, M.S."
institute: "University of Wisconsin-Madison"
date: "April 11, 2024"
format: 
  revealjs:
    incremental: true
    scrollable: true
    chalkboard: false
    css: slides.css
    background-color: dark-gray
fig-cap-location: top
editor_options: 
  chunk_output_type: console
---
## Acknowledgements

:::: {.columns}

::: {.column width="40%"}
- Project Co-Authors
  - Ariela Papp
  - Kendra Wyant
  - Sarah Sant'Ana
  - John Curtin (PI)
:::

::: {.column width="60%"}
- Parent Project
  - Susan Wanta (project administration, data curation)
  - Candace Lightheart (data collection)
  - Kerry Keiser (data collection)
  - Megan Schultz (data collection)
  - Jill Nagler (data collection)
  - Chris Gioia (clinical supervision)
  - Xiaojin (Jerry) Zhu (project conceptualization, analyses)
:::

::::

- Funding
  - This research was supported by grants from NIAAA (R01 AA024391; Curtin) and NIDA (R01 DA047315; Curtin)
  - This investigator was supported by a grant from NIDA (F31 DA056144; Fronk)

## Self-monitoring during AUD recovery

[Self-monitoring]{.purple} is a tool to increase conscious awareness about one's own present or future behavior

::: {.notes}
Self-monitoring = insight = confidence/likelihood of behaviors

It can bring about awareness of current behaviors, but it can also encourage thinking about the likelihood of future behaviors
:::

## Self-monitoring during AUD recovery

[Self-monitoring]{.purple} is a tool to increase conscious awareness about one's own present or [future]{.yellow} behavior

::: {.notes}
In the case of alcohol use disorder (AUD), self-monitoring is often used to increase awareness about CURRENT RISK of FUTURE ALCOHOL USE, especially a return to drinking that is goal-inconsistent. For example, if someone's goal is abstinence, then they may wish to self-monitor risk of any alcohol use.
:::

## Self-monitoring during AUD recovery

- Self-monitoring is...
  - Encouraged by clinicians
  - Prompted by many self-help tools/apps/etc.
  - Considered to be a productive component of CBT in the treatment of substance use disorders

::: {.notes}
There is a strongly held belief that self-monitoring is valuable and even necessary tool during AND FOLLOWING treatment for alcohol use disorder (AUD) and other substance use disorders. Often, self-monitoring is "prescribed" as a primary tool post-treatment as a way for individuals to determine whether they need to return to treatment or reach out for support. 
:::

## Static measurement

- Self-monitoring has traditionally been measured statically
  - Measures like the [Alcohol Abstinence Self-Efficacy Scale (AASE)]{.yellow} are often used to assess an individual's "long-term" likelihood of remaining abstinent
  - Scores from measures like the AASE may be used at the end of treatment/end of study/etc. to estimate an individual's future likelihood of staying abstinent

[It is unclear how well static measures like the AASE predict future lapse and relapse outcomes]{.purple}.

::: {.footer}
McKiernan et al. (2011). Development of a brief abstinence self-efficacy measure. *Journal of social work practice in the addictions.*
:::

## Recovery as a dynamic process

- Risk of lapse/relapse is best understood [dynamically]{.yellow}
  - Relapse prevention model has been updated to reflect dynamic processes
  - Fluctuating risk over time due to fluctuating proximal and distal risk factors that interact fluidly with one another
  
[Thus, self-monitoring dynamic risk of lapse likely requires dense, dynamic assessment to be effective]{.purple}

::: {.notes}
Static or one-time measurement stands in conflict with what we know about the dynamic relapse prevention model
:::

## Dynamic self-monitoring via EMA

- Ecological momentary assessment (EMA) offers a method by which individuals can self-monitor
  - [Densely]{.yellow}: assessment can happen as frequently as needed/desired
  - [Longitudinally]{.yellow}: assessment can happen throughout the ongoing process of recovery

::: {.notes}

:::

## Purpose

[The purpose of this project is to determine whether we can [predict alcohol lapse]{.yellow} more accurately using [dynamic self-monitoring]{.purple} or [static (one-time) risk assessment]{.purple}.]{.centered}

<!--progress through brief explanations of each in second column
1. brief overview: put question back up, model built from single predictor (kept "raw") matched to outcome of the same 1-week window, did they actually lapse. model performance = index of accuracy of their predictions

2. compared that 1-predictor model to a model built from a single AASE measurement at study intake. 

3. built model using all EMA data from the same study period (i.e., all questions) with more advanced feature engineering techniques to predict same 1-week outcome windows. compared how well we can predict using this "full" model to the dynamic assessment only model (how much better can we do if we take all the data into account, what else does it allow us to do with the outcome [treatment recs])
-->

## Participants

- Participants in early recovery (1-8 weeks abstinence) from moderate or severe AUD with a goal of abstinence

- Total sample: N = 151
  - Age: mean = 41, range 21 - 72
  - Sex: 49.0% female, 51.0% male
  - Race: 86.8% White/Caucasian, 5.3% Black/African American, 4.6% Other/Multiracial, 2.0% American Indian/Alaska Native, 1.3% Asian
  - Ethnicity: 97.4% Non-Hispanic, 2.6% Hispanic/Latino/Spanish origin
  - Education: 10.0% High school degree or less, 36.5% Some college, 53.6% College or advanced degree
  - Personal income: mean = 34,298, range 0 - 200,000
  
## Procedure

- Participants completed 5 study visits over ~3 months
- Intake visit included collecting self-report measures
- Participants were expected to respond to ecological momentary assessment (EMA) surveys daily while on study

## Static risk assessment via AASE

- During the intake visit, participants completed the [Alcohol Abstinence Self-Efficacy Scale]{.yellow}

- 20-item version that comprises the [confidence domain]{.purple} of the 40-item version
  - Measures an individual's *self-confidence about their ability to avoid drinking alcohol* in a variety of situations
  - Response options range from 0 ("Not at all") to 4 ("Extremely")
  
- Total score is calculated by summing all item scores

::: {.footer}
McKiernan et al. (2011). Development of a brief abstinence self-efficacy measure. *Journal of social work practice in the addictions.*
:::

::: {.notes}
4 subdomains re: different situations - negative affect (e.g., "When I am worried"), social (e.g., When I am being offered a drink in a social situation"), physical (e.g., "When I have a headache"), craving (e.g., "When I have the urge to try just one drink to see what happens")
:::

## Dynamic self-monitoring via EMA

- Dynamic self-monitoring relied on a single EMA item:

> "How likely are you to drink alcohol in the next week?"

- Participants responded on a 1 - 11 Likert scale with the following anchors:
  - 1 Very unlikely
  - 4-5 Unlikely
  - 7-8 Likely
  - 11 Very likely

- This item appeared on an EMA sent 1X daily in the morning
- Participants provided EMA data for up to 3 months

## Dynamic self-monitoring via EMA

![](https://github.com/jjcurtin/study_insight/blob/main/images/hist_insight.png)

## Outcome: Lapse

:::: {.columns}

::: {.column width="65%"}

- [Lapse]{.yellow}: A single instance of goal-inconsistent alcohol use

:::

::: {.column width="35%"}
:::

::::

::: {.notes}
justify lapse choice: clearly defined, observable, have temporally precise onsets and offsets. lapses always precede relapse and can be an early warning sign for intervention. maladaptive responses to a lapse can undermine recovery

connect to sample w goal of abstinence, any drinking = goal-inconsistent. made our outcome more homogeneous
:::

## Outcome: Lapse

:::: {.columns}

::: {.column width="65%"}

- [Lapse]{.yellow}: A single instance of goal-inconsistent alcohol use

- Lapses were assessed via an additional EMA item:

> "Have you drank any alcohol that you have not yet reported?

:::

::: {.column width="35%"}
![EMA Responses on Mobile Phone](https://github.com/jjcurtin/study_insight/blob/main/images/ema_lapse_mobile.png)
:::

::::

## Outcome: Lapse

:::: {.columns}

::: {.column width="65%"}

- [Lapse]{.yellow}: A single instance of goal-inconsistent alcohol use

- Lapses were assessed via an additional EMA item:

> "Have you drank any alcohol that you have not yet reported?

- If participants answered yes to this question, they were prompted to enter:
  - The hour and date of the start of the drinking episode
  - The hour and date of the end of the drinking episode

:::

::: {.column width="35%"}
![EMA Calendar Pop-up on Mobile Phone](https://github.com/jjcurtin/study_insight/blob/main/images/ema_cal_mobile.png)
:::

::::

## Lapse labels

- Our outcomes were [one-week windows]{.yellow} that began immediately following the submission of the morning EMA
  - Windows that contained any portion of a reported lapse were labeled as [lapse]{.purple}
  - Windows that did not contain a lapse were labeled as [no lapse]{.purple}

- Total N observations (i.e., 1-week windows): 9845
  - Lapse: 2442 (24.8%)
  - No lapse: 7403 (75.2%)

## Model configurations

- Single predictor in each model: 
  - Dynamic self-monitoring: most recent self-monitoring score (no feature engineering)
  - Static risk assessment: AASE total score (no feature engineering, same score for all outcome windows)
- Outcome: next-week drinking

- Model configurations used the xgboost algorithm, various types of resampling, and sensible hyperparameter values

::: {.notes}
  - Algorithm xgboost (tree-based algorithm)
  - Upsampling, downsampling, SMOTE, and no resampling to adjust majority/minority class ratios
  - Sensible values for hyperparameters mtry, learning rate, and tree depth
:::

## Model training, selection, and evaluation

::: {.columns}

:::: {.column width="60%"}
- Models are trained, selected, and evaluated using [nested k-fold cross-validation]{.yellow}

- Key details:
  - Training, selection, and evaluation happens in different data
  - Grouped by participant
  - Produces 30 independent estimates of model performance in new data
  
- Model performance evaluated on [area under the ROC curve (auROC)]{.yellow}
::::

:::: {.column width="40%"}
![](https://github.com/jjcurtin/study_insight/blob/main/images/cross_validation.png)
::::

:::

::: {.notes}
for people who actually know/care, we used 3 repeats of 10-fold CV on the outer fold and 1 repeat of 10-fold CV on the inner fold

walk through CV illustration. highlight key points

describe auROC in plain terms

:::

## Analysis plan: Model performance comparisons

- We used a [Bayesian hierarchical generalized linear model]{.purple} to estimate the posterior probability distributions and 95% Bayesian confidence intervals (CIs) for auROC for the best models

- [Model performance]{.yellow}: Report 95% (equal-tailed) Bayesian CIs from the posterior probability distributions

- [Model comparison]{.yellow}: Regressed the auROCs from the 30 test sets as a function of assessment type (dynamic vs. static), report 95% Bayesian CIs for the differences in performance

::: {.notes}
we have 30 held-out estimates from each model, so can compare performance using these independent estimates & bayesian approach, reference, tidymodels/tidyposterior methods

Followed recommendations from tidymodels team, random intercepts for fold and repeat (folds nested within repeats)
:::

## Results: Dynamic vs. static self-monitoring

{{< embed ../notebooks/ana_bayes_insight.qmd#fig-post-model-sm >}}

::: {.notes}
start with just AASE performance - some signal, unsurprising given extant literature and continued use in clinical practice!

dynamic self-monitoring allows us to do SO MUCH better! makes sense because we are assessing a process that we know to be dynamic
:::

## Results: Dynamic vs. static self-monitoring

{{< embed ../notebooks/ana_bayes_insight.qmd#fig-post-contrasts-sm >}}

::: {.notes}
statistically much better
contextualize ~.2 increase as 40% of possible auROC change - that's a HUGE effect size!
:::

## Takeaways

what did we learn

what can we do with this? not much --> full EMA

## Dynamic self-monitoring via EMA (UPDATE - this = WHY dynamic better)

Self-monitoring was...
- [**Dynamic**]{.purple}: Assessments occurred [*daily*]{.yellow}
- [**Cued**]{.purple}: Individuals were [*prompted*]{.yellow} to reflect on their risk
- [**Contextualized**]{.purple}: Self-monitoring question was situated [within a 10-item EMA]{.yellow}
  - 6 questions assessing risk factors 
  - 2 additional questions monitoring future behavior
  - Self-monitoring item was the [*final*]{.yellow} item, requiring reflection on 9 relevant risk factors prior to answering
  
<!-- consider if this slide is better suited as part of conclusions? re: WHY dynamic self-monitoring works well & works better than static measurement? YES MOVE LATER -->

## EMA

more methods details here on EMA, all items

discuss 4x daily component & timing

## Feature engineering

## Analyses model comparisons purpose 3

## Results: Full EMA vs. self-monitoring alone

{{< embed ../notebooks/ana_bayes_insight.qmd#fig-post-model-ema >}}

::: {.notes}

:::

## Results: Full EMA vs. self-monitoring alone

{{< embed ../notebooks/ana_bayes_insight.qmd#fig-post-contrasts-ema >}}

::: {.notes}

:::

don't introduce dtx until after initial model comparison
cut first question separately, just do model comparison 2 and talk about individual performance as well as modelc omparison in those analyses

then dtx - what would we DO with that information? nothing. need context and solutions

- Continuous monitoring with EMA can be embedded within a digital therapeutic context that can allow:
  - Simultaneous monitoring of other risk factors
  - Access to supports and tools to be used throughout recovery