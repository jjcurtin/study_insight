{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses & Results Outline\n",
    "\n",
    "Gaylen Fronk  \n",
    "Invalid Date\n",
    "\n",
    "## Full Knit Files\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/3_eval_outer_v2.html\" target=\"_blank\">Evaluate Outer Loop Performance &amp; SHAP Values</a>\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/ana_bayes_insight.html\" target=\"_blank\">Bayesian Analyses: Model comparisons &amp; Posterior distributions</a>\n",
    "\n",
    "## Analysis Plan\n",
    "\n",
    "### Key Questions\n",
    "\n",
    "The purpose of this project is to determine:\n",
    "\n",
    "1.  The accuracy of individuals’ insight into their lapse risk (in the next week)\n",
    "\n",
    "*Relevant model configurations*\n",
    "\n",
    "1 week windows ~ insight only (raw)\n",
    "\n",
    "1.  Whether dynamic assessment of insight and lapse risk has more predictive value than static assessment of insight and/or lapse risk\n",
    "\n",
    "*Relevant model configurations*\n",
    "\n",
    "1 week windows ~ insight only (raw)\n",
    "\n",
    "1 week windows ~ AASE total score only –\\> comparable to how an individual might currently use their own post-treatment insight to assess ongoing lapse risk\n",
    "\n",
    "Dichotomous lapse (whether an individual lapsed or not during study period) ~ AASE total score only –\\> comparable to how a clinician might use post-treatment insight to determine whether an individual should leave or continue treatment\n",
    "\n",
    "1.  Whether models that take advantage of full EMA data & feature engineering can predict lapse risk more accurately than insight alone\n",
    "\n",
    "*Relevant model configurations*\n",
    "\n",
    "1 week windows ~ insight only (raw)\n",
    "\n",
    "1 week windows ~ all EMA items (4x daily surveys, engineered features)\n",
    "\n",
    "## Model Performance\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/3_eval_outer_v2.html#inner-loop-auc\" target=\"_blank\">Inner loop performance</a>\n",
    "\n",
    "Already seeing some separation in model performance (all \\> insight only \\> AASE only models).\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/3_eval_outer_v2.html#outer-auc\" target=\"_blank\">Outer loop performance &amp; Drop off (inner –&gt; outer loop)</a>\n",
    "\n",
    "We see much larger drop-off for AASE only models (perhaps suggesting less signal). Gaps between models widen in the outer loop.\n",
    "\n",
    "## Visualize Comparisons of outer loop AUCs\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/3_eval_outer_v2.html#roc-curve\" target=\"_blank\">Faceted AUC histograms (all model configurations)</a>\n",
    "\n",
    "Very wide spread of AUCs for AASE only models.\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/3_eval_outer_v2.html#roc-curve\" target=\"_blank\">Overlaid AUC density plots</a>\n",
    "\n",
    "I like the idea of this figure, might be a good starting point for a primary figure for the paper.\n",
    "\n",
    "## SHAP Values\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/3_eval_outer_v2.html#feature-importance\" target=\"_blank\">Grouped global SHAP values</a>\n",
    "\n",
    "SHAP values are really only meaningful here for the all feature models. These will help us demonstrate the value of asking other EMA questions as they can help us determine WHY someone is at risk of lapsing and, consequently, which treatments/tools/supports may benefit them in the moment.\n",
    "\n",
    "However, it is interesting to see how the SHAP values differ for the single-feature models.\n",
    "\n",
    "## Posterior Distributions around Individual Model Performance\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/ana_bayes_insight.html#model-posterier-cis\" target=\"_blank\">Confidence Intervals</a>\n",
    "\n",
    "Tight confidence intervals around AUCs. CIs for the insight only & all feature models are well above 0.5. AASE only models are above 0.5 but not very much. Not sure if we’d want/need any additional demonstration of this fact?\n",
    "\n",
    "## Model Comparisons\n",
    "\n",
    "We compare insight only model to all other models to answer our key questions.\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/ana_bayes_insight.html#model-contrasts\" target=\"_blank\">Posterior distributions for model comparisons</a>\n",
    "\n",
    "Insight model performs better (ROPE of .01, .05) than AASE 1-week and dichotomous models (Key Question 2).\n",
    "\n",
    "All feature model perofrms better (ROPE of .01, .05) than insight only model (Key QUestion 3).\n",
    "\n",
    "<a href=\"file:///P:/StudyData/risk/knits/insight/ana_bayes_insight.html#plots\" target=\"_blank\">Nicer plots</a>"
   ],
   "id": "b9feaefe-fe99-4993-9894-ca88441b076b"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
