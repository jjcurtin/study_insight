{
  "hash": "4cfc370e650a261d7328e3ddda34b307",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Posterior probabilities across models for Insight study (version x86_64-w64-mingw32, x86_64, mingw32, ucrt, x86_64, mingw32, , 4, 3.2, 2023, 10, 31, 85441, R, R version 4.3.2 (2023-10-31 ucrt), Eye Holes)\"\nauthor: \"John Curtin\"\ndate: \"2024-04-04\"\nformat:\n  html:\n    embed-resources: true\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\neditor_options: \n  chunk_output_type: console\n---\n\n\n### Code Status\n\nIn use with iterative improvement.\n\nUpdating for use with study-insight\n\n### Notes\nCan review online docs for \n\n* [how to use rstanarm](https://cran.r-project.org/web/packages/rstanarm/vignettes/rstanarm.html)\n* [priors](https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html)\n* [warnings](https://mc-stan.org/misc/warnings.html)\n* [tutorial on rstanarm and shinystan](https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf)\n* [R Bloggers on perf_mod](https://www.r-bloggers.com/2019/12/tidyposteriors-bayesian-approach-to-model-comparison/)\n\n### Set Up Environment\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nstudy <- \"insight\"\nversion <- \"v2\"\n```\n:::\n\n\n\n\nPackages for script\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyposterior)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.6     ✔ workflows    1.1.3\n✔ modeldata    1.3.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.3.0\n✔ recipes      1.0.9     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ntheme_set(theme_classic()) \n```\n:::\n\n\nAbsolute paths\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nswitch (Sys.info()[['sysname']],\n        # PC paths\n        Windows = {\n          path_shared <- str_c(\"P:/studydata/risk/data_processed/shared\")\n          path_processed <- str_c(\"P:/studydata/risk/data_processed/\", study)\n          path_models <- str_c(\"P:/studydata/risk/models/\", study)},\n        \n        # IOS paths\n        Darwin = {\n          path_shared <- str_c(\"P:/studydata/risk/data_processed/shared\")\n          path_processed <- str_c(\"/Volumes/private/studydata/risk/data_processed/\",\n                                  study)\n          path_models <- str_c(\"/Volumes/private/studydata/risk/models/\",\n                               study)},\n        \n        # Linux paths\n        Linux = {\n          path_shared <- str_c(\"~/mnt/private/studydata/risk/data_processed/shared\")\n          path_processed <- str_c(\"~/mnt/private/studydata/risk/data_processed/\",\n                                  study)\n          path_models <- str_c(\"~/mnt/private/studydata/risk/models/\",\n                               study)}\n)\n```\n:::\n\n\n\nChunk Defaults\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\nknitr::opts_chunk$set(attr.output='style=\"max-height: 500px;\"')\n\noptions(tibble.width = Inf)\noptions(tibble.print_max = Inf)\n```\n:::\n\n\n\nSource training controls \n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# EDA\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"c045eee2655a18dc85e715b78182f176327358a7\"\n```\n\n\n:::\n:::\n\n\n\n### Read in preds and metrics for best model\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauc_1w_all <- read_rds(file.path(path_models, \n                                 str_c(\"outer_metrics_1week_all_\", \n                                       version, \"_nested.rds\"))) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10), 3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc_1w_ins <- read_rds(file.path(path_models, \n                                 str_c(\"outer_metrics_1week_insight_only_\", \n                                       version, \"_nested.rds\"))) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc_1w_aase <- read_rds(file.path(path_models, \n                                  str_c(\"outer_metrics_1week_aase_only_\", \n                                        version, \"_nested.rds\"))) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc <- auc_1w_all %>% \n  rename(week_all = roc_auc) %>% \n  mutate(week_ins = auc_1w_ins$roc_auc,\n         week_aase = auc_1w_aase$roc_auc) %>% \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nRows: 30\nColumns: 5\n$ repeat_num <chr> \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"repeat1\", \"rep…\n$ fold_num   <chr> \"fold1\", \"fold2\", \"fold3\", \"fold4\", \"fold5\", \"fold6\", \"fold…\n$ week_all   <dbl> 0.8932005, 0.8348008, 0.8794932, 0.8339037, 0.8352377, 0.89…\n$ week_ins   <dbl> 0.7975388, 0.6875551, 0.8691016, 0.6514497, 0.8116925, 0.79…\n$ week_aase  <dbl> 0.7859752, 0.4456172, 0.6300183, 0.4173161, 0.5234222, 0.62…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauc_1w_all %>% \n  ggplot() + \n  geom_histogram(aes(x = roc_auc), bins = 10)\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/auc_plots-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nauc_1w_ins %>% \n  ggplot() + \n  geom_histogram(aes(x = roc_auc), bins = 10)\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/auc_plots-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nauc_1w_aase %>% \n  ggplot() + \n  geom_histogram(aes(x = roc_auc), bins = 10)\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/auc_plots-3.png){width=672}\n:::\n:::\n\n\n### All models\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# from ?perf_mod()\n# Repeated CV (id = repeat, id2 = fold within repeat)\n# with a common variance:  statistic ~ model + (model | id2/id)\nset.seed(101)\npp <- auc |> \n  rename(id = repeat_num,\n         id2 = fold_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n           # prior_intercept = rstanarm::student_t(autoscale = TRUE),\n           # prior = rstanarm::student_t(autoscale = TRUE),\n           transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n           # iter = 2000, chains = 4,  \n           adapt_delta = .99,\n           # cores = 4, seed = 12345,\n           family = gaussian, \n  )  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.863 seconds (Warm-up)\nChain 1:                1.41 seconds (Sampling)\nChain 1:                3.273 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3.8e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.627 seconds (Warm-up)\nChain 2:                1.601 seconds (Sampling)\nChain 2:                3.228 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.7e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.404 seconds (Warm-up)\nChain 3:                0.943 seconds (Sampling)\nChain 3:                2.347 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.7e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.27 seconds (Warm-up)\nChain 4:                0.93 seconds (Sampling)\nChain 4:                2.2 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nrstanarm::prior_summary(pp$stan)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\nPriors for model 'pp$stan' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 1.2, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 1.2, scale = 2.2)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [0,0], scale = [2.5,2.5])\n  Adjusted prior:\n    ~ normal(location = [0,0], scale = [4.54,4.54])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 1.2)\n\nCovariance\n ~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)\n------\nSee help('prior_summary.stanreg') for more details\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(pp$stan)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      statistic ~ model + (1 | id2/id)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 90\n groups:       id:id2 (30), id2 (10)\n\nEstimates:\n                                        mean   sd   10%   50%   90%\n(Intercept)                            0.4    0.1  0.2   0.4   0.5 \nmodelweek_all                          1.6    0.1  1.5   1.6   1.7 \nmodelweek_ins                          1.0    0.1  0.9   1.0   1.1 \nb[(Intercept) id:id2:repeat1:fold1]    0.2    0.2 -0.1   0.2   0.4 \nb[(Intercept) id:id2:repeat1:fold10]  -0.1    0.2 -0.4  -0.1   0.1 \nb[(Intercept) id:id2:repeat1:fold2]   -0.1    0.2 -0.4  -0.1   0.1 \nb[(Intercept) id:id2:repeat1:fold3]    0.1    0.2 -0.1   0.1   0.4 \nb[(Intercept) id:id2:repeat1:fold4]   -0.2    0.2 -0.5  -0.2   0.1 \nb[(Intercept) id:id2:repeat1:fold5]   -0.1    0.2 -0.3  -0.1   0.1 \nb[(Intercept) id:id2:repeat1:fold6]    0.0    0.2 -0.3   0.0   0.2 \nb[(Intercept) id:id2:repeat1:fold7]   -0.1    0.2 -0.4  -0.1   0.1 \nb[(Intercept) id:id2:repeat1:fold8]    0.1    0.2 -0.2   0.0   0.3 \nb[(Intercept) id:id2:repeat1:fold9]    0.4    0.3  0.1   0.4   0.8 \nb[(Intercept) id:id2:repeat2:fold1]    0.0    0.2 -0.2   0.0   0.2 \nb[(Intercept) id:id2:repeat2:fold10]   0.3    0.3  0.0   0.3   0.7 \nb[(Intercept) id:id2:repeat2:fold2]   -0.2    0.2 -0.5  -0.1   0.1 \nb[(Intercept) id:id2:repeat2:fold3]   -0.1    0.2 -0.3  -0.1   0.2 \nb[(Intercept) id:id2:repeat2:fold4]   -0.1    0.2 -0.3  -0.1   0.2 \nb[(Intercept) id:id2:repeat2:fold5]    0.0    0.2 -0.2   0.0   0.3 \nb[(Intercept) id:id2:repeat2:fold6]    0.0    0.2 -0.2   0.0   0.3 \nb[(Intercept) id:id2:repeat2:fold7]    0.0    0.2 -0.3   0.0   0.2 \nb[(Intercept) id:id2:repeat2:fold8]    0.2    0.2  0.0   0.2   0.5 \nb[(Intercept) id:id2:repeat2:fold9]   -0.3    0.2 -0.6  -0.3   0.0 \nb[(Intercept) id:id2:repeat3:fold1]   -0.1    0.2 -0.4  -0.1   0.1 \nb[(Intercept) id:id2:repeat3:fold10]   0.2    0.2 -0.1   0.2   0.5 \nb[(Intercept) id:id2:repeat3:fold2]    0.0    0.2 -0.3   0.0   0.2 \nb[(Intercept) id:id2:repeat3:fold3]    0.1    0.2 -0.2   0.1   0.3 \nb[(Intercept) id:id2:repeat3:fold4]    0.0    0.2 -0.3   0.0   0.3 \nb[(Intercept) id:id2:repeat3:fold5]    0.0    0.2 -0.2   0.0   0.3 \nb[(Intercept) id:id2:repeat3:fold6]    0.2    0.2 -0.1   0.2   0.5 \nb[(Intercept) id:id2:repeat3:fold7]   -0.2    0.2 -0.5  -0.2   0.1 \nb[(Intercept) id:id2:repeat3:fold8]   -0.3    0.2 -0.6  -0.3   0.0 \nb[(Intercept) id:id2:repeat3:fold9]    0.0    0.2 -0.2   0.0   0.3 \nb[(Intercept) id2:fold1]               0.0    0.2 -0.2   0.0   0.3 \nb[(Intercept) id2:fold10]              0.4    0.2  0.1   0.4   0.7 \nb[(Intercept) id2:fold2]              -0.3    0.2 -0.6  -0.3   0.0 \nb[(Intercept) id2:fold3]               0.1    0.2 -0.1   0.1   0.3 \nb[(Intercept) id2:fold4]              -0.2    0.2 -0.5  -0.2   0.0 \nb[(Intercept) id2:fold5]               0.0    0.2 -0.2   0.0   0.2 \nb[(Intercept) id2:fold6]               0.2    0.2 -0.1   0.2   0.4 \nb[(Intercept) id2:fold7]              -0.3    0.2 -0.5  -0.3   0.0 \nb[(Intercept) id2:fold8]               0.0    0.2 -0.2   0.0   0.2 \nb[(Intercept) id2:fold9]               0.1    0.2 -0.1   0.1   0.4 \nsigma                                  0.4    0.0  0.4   0.4   0.5 \nSigma[id:id2:(Intercept),(Intercept)]  0.1    0.1  0.0   0.1   0.1 \nSigma[id2:(Intercept),(Intercept)]     0.1    0.1  0.0   0.1   0.2 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 1.2    0.1  1.1   1.2   1.3  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                      mcse Rhat n_eff\n(Intercept)                           0.0  1.0  1713 \nmodelweek_all                         0.0  1.0  3721 \nmodelweek_ins                         0.0  1.0  4769 \nb[(Intercept) id:id2:repeat1:fold1]   0.0  1.0  2660 \nb[(Intercept) id:id2:repeat1:fold10]  0.0  1.0  2206 \nb[(Intercept) id:id2:repeat1:fold2]   0.0  1.0  1663 \nb[(Intercept) id:id2:repeat1:fold3]   0.0  1.0  3556 \nb[(Intercept) id:id2:repeat1:fold4]   0.0  1.0  1780 \nb[(Intercept) id:id2:repeat1:fold5]   0.0  1.0  4003 \nb[(Intercept) id:id2:repeat1:fold6]   0.0  1.0  3393 \nb[(Intercept) id:id2:repeat1:fold7]   0.0  1.0  2065 \nb[(Intercept) id:id2:repeat1:fold8]   0.0  1.0  4422 \nb[(Intercept) id:id2:repeat1:fold9]   0.0  1.0   995 \nb[(Intercept) id:id2:repeat2:fold1]   0.0  1.0  4432 \nb[(Intercept) id:id2:repeat2:fold10]  0.0  1.0  1038 \nb[(Intercept) id:id2:repeat2:fold2]   0.0  1.0  1585 \nb[(Intercept) id:id2:repeat2:fold3]   0.0  1.0  3592 \nb[(Intercept) id:id2:repeat2:fold4]   0.0  1.0  2127 \nb[(Intercept) id:id2:repeat2:fold5]   0.0  1.0  4586 \nb[(Intercept) id:id2:repeat2:fold6]   0.0  1.0  2872 \nb[(Intercept) id:id2:repeat2:fold7]   0.0  1.0  2492 \nb[(Intercept) id:id2:repeat2:fold8]   0.0  1.0  1728 \nb[(Intercept) id:id2:repeat2:fold9]   0.0  1.0  1956 \nb[(Intercept) id:id2:repeat3:fold1]   0.0  1.0  3804 \nb[(Intercept) id:id2:repeat3:fold10]  0.0  1.0  1238 \nb[(Intercept) id:id2:repeat3:fold2]   0.0  1.0  2605 \nb[(Intercept) id:id2:repeat3:fold3]   0.0  1.0  4107 \nb[(Intercept) id:id2:repeat3:fold4]   0.0  1.0  3034 \nb[(Intercept) id:id2:repeat3:fold5]   0.0  1.0  5145 \nb[(Intercept) id:id2:repeat3:fold6]   0.0  1.0  1576 \nb[(Intercept) id:id2:repeat3:fold7]   0.0  1.0  1653 \nb[(Intercept) id:id2:repeat3:fold8]   0.0  1.0  1794 \nb[(Intercept) id:id2:repeat3:fold9]   0.0  1.0  2847 \nb[(Intercept) id2:fold1]              0.0  1.0  2558 \nb[(Intercept) id2:fold10]             0.0  1.0  1111 \nb[(Intercept) id2:fold2]              0.0  1.0  1054 \nb[(Intercept) id2:fold3]              0.0  1.0  2343 \nb[(Intercept) id2:fold4]              0.0  1.0  1374 \nb[(Intercept) id2:fold5]              0.0  1.0  2710 \nb[(Intercept) id2:fold6]              0.0  1.0  2038 \nb[(Intercept) id2:fold7]              0.0  1.0  1175 \nb[(Intercept) id2:fold8]              0.0  1.0  2693 \nb[(Intercept) id2:fold9]              0.0  1.0  2027 \nsigma                                 0.0  1.0  1359 \nSigma[id:id2:(Intercept),(Intercept)] 0.0  1.0   765 \nSigma[id2:(Intercept),(Intercept)]    0.0  1.0  1165 \nmean_PPD                              0.0  1.0  4157 \nlog-posterior                         0.3  1.0   652 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# shinystan::launch_shinystan(pp$stan)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp %>%  write_rds(file.path(path_models, \n                            str_c(\"posteriors_\", version, \"_nested.rds\")))\n```\n:::\n\n\n### Model posterier CIs\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_tidy <- pp %>% \n  tidy(seed = 123)\n\nq = c(.025, .5, .975)\npp_tidy %>% \n  group_by(model) %>% \n  summarize(median = quantile(posterior, probs = q[2]),\n            lower = quantile(posterior, probs = q[1]), \n            upper = quantile(posterior, probs = q[3])) %>% \n  mutate(model = factor(model, \n                        levels = c(\"week_aase\", \"week_ins\", \n                                   \"week_all\"),\n                        labels = c(\"AASE Static Risk\",\n                                   \"Dynamic Self-Monitoring\", \n                                   \"Full Features\")),\n         y = 1000) |> \n  arrange(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n# A tibble: 3 × 5\n  model                   median lower upper     y\n  <fct>                    <dbl> <dbl> <dbl> <dbl>\n1 AASE Static Risk         0.588 0.524 0.652  1000\n2 Dynamic Self-Monitoring  0.795 0.749 0.837  1000\n3 Full Features            0.876 0.843 0.902  1000\n```\n\n\n:::\n:::\n\n\n### Model contrasts\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_contrasts <- contrast_models(pp, \n                                list(\"week_ins\", \"week_ins\"), \n                                list(\"week_aase\", \"week_all\"))\n\nsummary(pp_contrasts, size = 0.01, prob = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```{style=\"max-height: 500px;\"}\n# A tibble: 2 × 9\n  contrast              probability    mean  lower   upper  size pract_neg\n  <chr>                       <dbl>   <dbl>  <dbl>   <dbl> <dbl>     <dbl>\n1 week_ins vs week_aase           1  0.206   0.160  0.254   0.01         0\n2 week_ins vs week_all            0 -0.0803 -0.113 -0.0493  0.01         1\n  pract_equiv pract_pos\n        <dbl>     <dbl>\n1           0         1\n2           0         0\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\npp_contrasts %>% autoplot(size = 0)\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n### Plots\n\nModel posteriors\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci <- pp_tidy %>% \n  summary() %>% \n  mutate(model = factor(model, \n                        levels = c(\"week_aase\", \"week_ins\", \n                                   \"week_all\"),\n                        labels = c(\"AASE Static Risk\",\n                                   \"Dynamic Self-Monitoring\", \n                                   \"Full Features\")),\n         y = 1000)\n\nci_sm <- ci |> \n  filter(model != \"Full Features\")\n\nci_ema <- ci |> \n  filter(model != \"AASE Static Risk\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: fig_post_model_all\n\npp_tidy %>% \n  mutate(model = factor(model, \n                        levels = c(\"week_aase\", \"week_ins\", \n                                   \"week_all\"),\n                        labels = c(\"AASE Static Risk\",\n                                   \"Dynamic Self-Monitoring\", \n                                   \"All Features\")),\n         y = 1000) %>%\n  ggplot() + \n  geom_histogram(aes(x = posterior, fill = model), \n                 color = \"black\", alpha = .4, \n                 bins = 30) +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean,\n                             color = model),\n               data = ci) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, \n                             xend = upper, color = model),\n               data = ci) +\n  facet_wrap(vars(model), ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", \n                     breaks = c(0, 500, 1000)) +\n  # ylab(\"Posterior Probability Density\") +\n  xlab(\"Area Under ROC Curve (auROC)\") +\n  labs(color = \"Model\", fill = \"Model\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/fig_post_model_all-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: fig_post_model_sm\n\npp_tidy %>% \n  mutate(model = factor(model, \n                        levels = c(\"week_aase\", \"week_ins\", \n                                   \"week_all\"),\n                        labels = c(\"AASE Static Risk\",\n                                   \"Dynamic Self-Monitoring\", \n                                   \"All Features\")),\n         y = 1000) %>%\n  filter(model != \"Full Features\") |> \n  ggplot() + \n  geom_histogram(aes(x = posterior, fill = model), \n                 color = \"black\", alpha = .4, \n                 bins = 30) +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean,\n                             color = model),\n               data = ci_sm) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, \n                             xend = upper, color = model),\n               data = ci_sm) +\n  facet_wrap(vars(model), ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", \n                     breaks = c(0, 500, 1000)) +\n  # ylab(\"Posterior Probability Density\") +\n  xlab(\"Area Under ROC Curve (auROC)\") +\n  labs(color = \"Model\", fill = \"Model\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/fig_post_model_sm-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: fig_post_model_ema\n\npp_tidy %>% \n  mutate(model = factor(model, \n                        levels = c(\"week_aase\", \"week_ins\", \n                                   \"week_all\"),\n                        labels = c(\"AASE Static Risk\",\n                                   \"Dynamic Self-Monitoring\", \n                                   \"All Features\")),\n         y = 1000) %>%\n  filter(model != \"AASE Static Risk\") |> \n  ggplot() + \n  geom_histogram(aes(x = posterior, fill = model), \n                 color = \"black\", alpha = .4, \n                 bins = 30) +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean,\n                             color = model),\n               data = ci_ema) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, \n                             xend = upper, color = model),\n               data = ci_ema) +\n  facet_wrap(vars(model), ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", \n                     breaks = c(0, 500, 1000)) +\n  # ylab(\"Posterior Probability Density\") +\n  xlab(\"Area Under ROC Curve (auROC)\") +\n  labs(color = \"Model\", fill = \"Model\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/fig_post_model_ema-1.png){width=672}\n:::\n:::\n\n\nmodel contrast posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci <- pp %>%\n  contrast_models(list(\"week_ins\", \"week_ins\"), \n                  list(\"week_aase\", \"week_all\")) %>% \n  summary(size = .01) %>% \n  mutate(contrast = factor(contrast, \n                           levels = c(\"week_ins vs week_aase\", \n                                      \"week_ins vs week_all\"),\n                           labels = c(\"Dynamic vs. Static self-monitoring\", \n                                      \"Self-monitoring only vs. All Features\")),\n         y = 700)\n\nci_sm <- ci |> \n  filter(str_detect(contrast, \"Dynamic\"))\n\nci_ema <- ci |> \n  filter(str_detect(contrast, \"All\")) |> \n  mutate(mean = mean * -1,\n         lower = lower * -1,\n         upper = upper * -1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: fig_post_contrasts_all\n\npp %>% \n  tidy(seed = 123) %>%   \n  group_by(model) %>% \n  mutate(sample = row_number()) %>% \n  ungroup() %>% \n  pivot_wider(names_from = model, values_from = posterior) %>% \n  mutate(ins_vs_aase = week_ins - week_aase,\n         ins_vs_all = week_ins - week_all) %>% \n  pivot_longer(cols = ins_vs_aase:ins_vs_all,\n               names_to = \"contrast\",\n               values_to = \"posterior\") %>% \n  mutate(contrast = factor(contrast, \n                           levels = c(\"ins_vs_aase\", \n                                      \"ins_vs_all\"),\n                           labels = c(\"Dynamic vs. Static self-monitoring\", \n                                      \"Self-monitoring only vs. All Features\"))) %>% \n  ggplot() +\n  geom_histogram(aes(x = posterior, fill = contrast), \n                 color = \"black\", alpha = .4, bins = 30) +\n  geom_vline(xintercept = -.01, color = \"yellow\", \n             linetype = \"dashed\", linewidth = 1) +\n  geom_vline(xintercept = .01, color = \"yellow\", \n             linetype = \"dashed\", linewidth = 1) +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean,\n                             color = contrast), data = ci) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper, \n                             color = contrast), data = ci) +\n  facet_wrap(~contrast, ncol = 1) +\n  ylab(\"Posterior Probability\") +\n  xlab(\"Model Contrast for auROC\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/fig_post_contrasts_all-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: fig_post_contrasts_sm\n\npp %>% \n  tidy(seed = 123) %>%   \n  group_by(model) %>% \n  mutate(sample = row_number()) %>% \n  ungroup() %>% \n  pivot_wider(names_from = model, values_from = posterior) %>% \n  mutate(ins_vs_aase = week_ins - week_aase,\n         ins_vs_all = week_ins - week_all) %>% \n  pivot_longer(cols = ins_vs_aase:ins_vs_all,\n               names_to = \"contrast\",\n               values_to = \"posterior\") %>% \n  mutate(contrast = factor(contrast, \n                           levels = c(\"ins_vs_aase\", \n                                      \"ins_vs_all\"),\n                           labels = c(\"Dynamic vs. Static self-monitoring\", \n                                      \"Self-monitoring only vs. All Features\"))) %>% \n  filter(str_detect(contrast, \"Dynamic\")) |> \n  ggplot() +\n  geom_histogram(aes(x = posterior, fill = contrast), \n                 color = \"black\", alpha = .4, bins = 30) +\n  geom_vline(xintercept = -.01, color = \"yellow\", \n             linetype = \"dashed\", linewidth = 1) +\n  geom_vline(xintercept = .01, color = \"yellow\", \n             linetype = \"dashed\", linewidth = 1) +\n  geom_segment(mapping = aes(y = y+200, yend = y, x = mean, xend = mean,\n                             color = contrast), data = ci_sm) +\n  geom_segment(mapping = aes(y = y+100, yend = y+100, x = lower, xend = upper, \n                             color = contrast), data = ci_sm) +\n  ylab(\"Posterior Probability\") +\n  xlab(\"Model Contrast for auROC\") +\n  labs(title = \"Dynamic vs. Static Self-Monitoring\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/fig_post_contrasts_sm-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: fig_post_contrasts_ema\n\npp %>% \n  tidy(seed = 123) %>%   \n  group_by(model) %>% \n  mutate(sample = row_number()) %>% \n  ungroup() %>% \n  pivot_wider(names_from = model, values_from = posterior) %>% \n  mutate(ins_vs_aase = week_ins - week_aase,\n         all_vs_ins = week_all - week_ins) %>% \n  pivot_longer(cols = ins_vs_aase:all_vs_ins,\n               names_to = \"contrast\",\n               values_to = \"posterior\") %>% \n  mutate(contrast = factor(contrast, \n                           levels = c(\"ins_vs_aase\", \n                                      \"all_vs_ins\"),\n                           labels = c(\"Dynamic vs. Static self-monitoring\", \n                                      \"All Features vs. Self-monitoring only\"))) %>% \n  filter(str_detect(contrast, \"All\")) |> \n  ggplot() +\n  geom_histogram(aes(x = posterior, fill = contrast), \n                 color = \"black\", alpha = .4, bins = 30) +\n  geom_vline(xintercept = -.01, color = \"yellow\", \n             linetype = \"dashed\", linewidth = 1) +\n  geom_vline(xintercept = .01, color = \"yellow\", \n             linetype = \"dashed\", linewidth = 1) +\n  geom_segment(mapping = aes(y = y+200, yend = y, x = mean, xend = mean,\n                             color = contrast), data = ci_ema) +\n  geom_segment(mapping = aes(y = y+100, yend = y+100, x = lower, xend = upper, \n                             color = contrast), data = ci_ema) +\n  ylab(\"Posterior Probability\") +\n  xlab(\"Model Contrast for auROC\") +\n  labs(title = \"All Features vs. Self-monitoring only\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](ana_bayes_insight_files/figure-html/fig_post_contrasts_ema-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "ana_bayes_insight_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}